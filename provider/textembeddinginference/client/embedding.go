package textembeddinginference

import (
	"go.jetify.com/ai/provider/textembeddinginference/client/option"
)

// EmbeddingService contains methods and other services that help with interacting
// with the embedding API.
//
// Note, unlike clients, this service does not read variables from the environment
// automatically. You should not instantiate this service directly, and instead use
// the [NewEmbeddingService] method instead.
type EmbeddingService struct {
	Options []option.RequestOption
}

type CreateEmbeddingResponse struct {
	// The list of embeddings generated by the model.
	Data []Embedding `json:"data"`
	// The name of the model used to generate the embedding.
	Model string `json:"model"`
	// The usage information for the request.
	Usage *CreateEmbeddingResponseUsage `json:"usage,omitempty"`
}

// The usage information for the request.
type CreateEmbeddingResponseUsage struct {
	// The number of tokens used by the prompt.
	PromptTokens int64 `json:"prompt_tokens"`
	// The total number of tokens used by the request.
	TotalTokens int64 `json:"total_tokens"`
}

// Represents an embedding vector returned by embedding endpoint.
type Embedding struct {
	// The embedding vector, which is a list of floats. The length of vector depends on the model.
	Embedding []float64 `json:"embedding"`
	// The index of the embedding in the list of embeddings.
	Index int64 `json:"index"`
}

// EmbeddingModel represents a TEI model identifier
type EmbeddingModel = string

// TEI typically uses the actual model name loaded in the service
// These are common model names that might be used with TEI
const (
	// Common text embedding models that can be used with TEI
	EmbeddingModelAllMiniLML6V2      EmbeddingModel = "sentence-transformers/all-MiniLM-L6-v2"
	EmbeddingModelAllMiniLML12V2     EmbeddingModel = "sentence-transformers/all-MiniLM-L12-v2"
	EmbeddingModelAllMpnetBaseV2     EmbeddingModel = "sentence-transformers/all-mpnet-base-v2"
	EmbeddingModelMultiQAMiniLML6COS EmbeddingModel = "sentence-transformers/multi-qa-MiniLM-L6-cos-v1"

	// BGE models
	EmbeddingModelBGESmallEN EmbeddingModel = "BAAI/bge-small-en"
	EmbeddingModelBGEBaseEN  EmbeddingModel = "BAAI/bge-base-en"
	EmbeddingModelBGELargeEN EmbeddingModel = "BAAI/bge-large-en"

	// E5 models
	EmbeddingModelE5SmallV2 EmbeddingModel = "intfloat/e5-small-v2"
	EmbeddingModelE5BaseV2  EmbeddingModel = "intfloat/e5-base-v2"
	EmbeddingModelE5LargeV2 EmbeddingModel = "intfloat/e5-large-v2"
)

type embeddingNewParams[T any] struct {
	// Input text to embed, encoded as a string or array of strings.
	Inputs T `json:"inputs"`
	// Whether to normalize the embeddings
	Normalize *bool `json:"normalize,omitempty"`
	// Whether to truncate the inputs if they exceed the model's maximum length
	Truncate *bool `json:"truncate,omitempty"`
}

// NewEmbeddingService generates a new service that applies the given options to
// each request. These options are applied after the parent client's options (if
// there is one), and before any request-specific options.
func NewEmbeddingService(opts ...option.RequestOption) (r EmbeddingService) {
	r = EmbeddingService{}
	r.Options = opts
	return r
}
